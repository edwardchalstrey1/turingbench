{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running code that requires CUDA enabled GPUs on multiple platforms\n",
    "====\n",
    "\n",
    "The following Python code: [mandelbrot_gpu.py](https://github.com/edwardchalstrey1/turingbench/blob/master/turingbench_python_cuda/mandelbrot_gpu/mandelbrot_gpu.py) creates a mandelbrot image, using Python's ```numba``` package with the CUDA toolkit on GPUs. For our purposes, let's just consider the time taken to create the image, which is printed (see line 57: [mandelbrot_gpu.py](https://github.com/edwardchalstrey1/turingbench/blob/master/turingbench_python_cuda/mandelbrot_gpu/mandelbrot_gpu.py)).\n",
    "\n",
    "This code was taken from [*harrism*'s notebook](https://github.com/harrism/numba_examples/blob/master/mandelbrot_numba.ipynb) featured in the [NVIDIA developer blog](https://devblogs.nvidia.com/numba-python-cuda-acceleration/).\n",
    "\n",
    "Dockerfile\n",
    "---\n",
    "\n",
    "The Dockerfile below specifies an image that can be used to create a container capable of running ```mandelbrot_gpu.py```.\n",
    "\n",
    "Running a CUDA container requires a machine with at least one CUDA-capable GPU and a driver compatible with the CUDA toolkit version you are using. Take a look at the requirements table [here](https://github.com/NVIDIA/nvidia-docker/wiki/CUDA#requirements).\n",
    "\n",
    "The machine running the CUDA container only requires the NVIDIA driver, the CUDA toolkit doesn't have to be installed.\n",
    "\n",
    "A Docker image has been built and pushed to [Docker Hub](https://cloud.docker.com/u/edwardchalstrey/repository/docker/edwardchalstrey/mandelbrot_gpu) with this Dockerfile:\n",
    "\n",
    "1. ```docker build -t edwardchalstrey/mandelbrot_gpu .```\n",
    "2. ```docker push edwardchalstrey/mandelbrot_gpu```\n",
    "\n",
    "It can then can be run with Docker, but requires nvidia-docker to also be installed:\n",
    "\n",
    "```nvidia-docker run edwardchalstrey/mandelbrot_gpu```\n",
    "\n",
    "If your platform doesn't have nvidia-docker, see the [installation instructions](https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM nvidia/cuda:9.0-cudnn7-runtime-ubuntu16.04\n",
    "\n",
    "RUN  apt-get update \\\n",
    "  && apt-get install -y wget vim bzip2\\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "\n",
    "#Install MINICONDA\n",
    "RUN wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O Miniconda.sh && \\\n",
    "    /bin/bash Miniconda.sh -b -p /opt/conda && \\\n",
    "    rm Miniconda.sh\n",
    "\n",
    "ENV PATH /opt/conda/bin:$PATH\n",
    "\n",
    "RUN conda install numpy scipy matplotlib numba cudatoolkit=9.0 pyculib -y\n",
    "\n",
    "COPY mandelbrot_gpu.py /mandelbrot_gpu.py\n",
    "\n",
    "CMD python3 mandelbrot_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singularity definition file\n",
    "-----\n",
    "\n",
    "The definition file below is based on the Docker image already built and pushed to Docker Hub and so is very simple.\n",
    "\n",
    "Singularity Commands to build from the Docker Hub image and run:\n",
    "\n",
    "1. ```singularity build mandelbrot_gpu.sif Singularity.mandelbrot_gpu```\n",
    "2. ```singularity run --nv mandelbrot_gpu.sif```\n",
    "\n",
    "*Note, the Singularity container needs to be run in the same dir as a file called ```mandelbrot_gpu.py``` for it to run this way. You may wish to not include anything in %files and instead specify the file to run in the run command.*\n",
    "\n",
    "In this case I have built the image with [Singularity Hub](https://www.singularity-hub.org/) by linking it to my [GitHub repo](https://github.com/edwardchalstrey1/turingbench/tree/master/turingbench_python_cuda/mandelbrot_gpu), which contains the definition file, named such that the image will be built on each commit.\n",
    "\n",
    "A container based on the image can then be run on any platform with Singularity with the following command (using the ```--nv``` option to leverage the nvidia GPU):\n",
    "\n",
    "```singularity run --nv shub://singularity-hub.org/edwardchalstrey1/turingbench:mandelbrot_gpu```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Singularity.mandelbrot_gpu\n"
     ]
    }
   ],
   "source": [
    "%%writefile Singularity.mandelbrot_gpu\n",
    "BootStrap: docker \n",
    "From: edwardchalstrey/mandelbrot_gpu\n",
    "\n",
    "%post\n",
    "    apt-get -y update\n",
    "\n",
    "%files      \n",
    "    mandelbrot_gpu.py /mandelbrot_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JADE submission script\n",
    "----\n",
    "\n",
    "To run a Singularity container based on this image on the [JADE HPC a submission script was required](http://docs.jade.ac.uk/en/latest/jade/scheduler/index.html).\n",
    "\n",
    "In JADE, make the submission script executable:\n",
    "```chmod +x jade_sub.sh```\n",
    "\n",
    "Then run with a command such as this:\n",
    "```srun --gres=gpu:1 -p small --pty jade_sub.sh```\n",
    "\n",
    "*Note: This works without loading JADE's CUDA module (e.g. ```module load cuda/9.0```) and loading it appears to break the link to the driver.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jade_sub.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile jade_sub.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# set the number of nodes\n",
    "#SBATCH --nodes=1\n",
    "\n",
    "# set max wallclock time\n",
    "#SBATCH --time=00:30:00\n",
    "\n",
    "# set name of job\n",
    "#SBATCH --job-name=echalstrey_singularity_cuda_test1\n",
    "\n",
    "# set number of GPUs\n",
    "#SBATCH --gres=gpu:4\n",
    "\n",
    "# mail alert at start, end and abortion of execution\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "# send mail to this address\n",
    "#SBATCH --mail-user=echalstrey@turing.ac.uk\n",
    "\n",
    "# run the application\n",
    "module load singularity\n",
    "singularity run --nv shub://singularity-hub.org/edwardchalstrey1/turingbench:mandelbrot_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "------\n",
    "\n",
    "I can now run ```mandelbrot_gpu.py``` on these platforms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Platform  | Container  | Mandelbrot creation time in s  |\n",
    "|---|---|---|\n",
    "| Azure (Nvidia K80)  | Docker  | 5.369710  |\n",
    "| Azure (Nvidia K80)  | Singularity 3.2  | 5.734466  |\n",
    "| CSD3 (Nvidia V100)  | Singularity  |   |\n",
    "| JADE (Nvidia P100)  | Singularity 2.4 | 0.934607  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
