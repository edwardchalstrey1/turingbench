{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running code that requires CUDA enabled GPUs on multiple platforms\n",
    "====\n",
    "\n",
    "The following Python code: [mandelbrot_gpu.py](https://github.com/edwardchalstrey1/turingbench/blob/master/turingbench_python_cuda/mandelbrot_gpu/mandelbrot_gpu.py) creates a mandelbrot image, using Python's ```numba``` package with the CUDA toolkit on GPUs. For our purposes, let's just consider the time taken to create the image, which is printed (see line 57: [mandelbrot_gpu.py](https://github.com/edwardchalstrey1/turingbench/blob/master/turingbench_python_cuda/mandelbrot_gpu/mandelbrot_gpu.py)).\n",
    "\n",
    "This code was taken from [*harrism*'s notebook](https://github.com/harrism/numba_examples/blob/master/mandelbrot_numba.ipynb) featured in the [NVIDIA developer blog](https://devblogs.nvidia.com/numba-python-cuda-acceleration/).\n",
    "\n",
    "Capable computing platforms\n",
    "----\n",
    "\n",
    "Running a CUDA container requires a machine with at least one CUDA-capable GPU and a driver compatible with the CUDA toolkit version you are using. Take a look at the requirements table [here](https://github.com/NVIDIA/nvidia-docker/wiki/CUDA#requirements).\n",
    "\n",
    "The machine running the CUDA container only requires the NVIDIA driver, the CUDA toolkit doesn't have to be installed.\n",
    "\n",
    "On a linux machine with NVIDIA GPU(s), the ```nvidia-smi``` command can be used to reveal the driver version and other useful information.\n",
    "\n",
    "Creating a Docker image\n",
    "---\n",
    "\n",
    "The Dockerfile below specifies an image that can be used to create a container capable of running ```mandelbrot_gpu.py```. Note that the base image is an official CUDA image from NVIDIA and that the ```cudatoolkit``` version installed with Anaconda (9.0) matches the CUDA version specified by the image.\n",
    "\n",
    "A Docker image has been built and pushed to [Docker Hub](https://cloud.docker.com/u/edwardchalstrey/repository/docker/edwardchalstrey/mandelbrot_gpu) with this Dockerfile:\n",
    "\n",
    "1. ```docker build -t edwardchalstrey/mandelbrot_gpu .```\n",
    "2. ```docker push edwardchalstrey/mandelbrot_gpu```\n",
    "\n",
    "It can then can be run with Docker, but requires nvidia-docker to also be installed:\n",
    "\n",
    "```nvidia-docker run edwardchalstrey/mandelbrot_gpu```\n",
    "\n",
    "If your platform doesn't have nvidia-docker, see the [installation instructions](https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0)#installing-version-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM nvidia/cuda:9.0-cudnn7-runtime-ubuntu16.04\n",
    "\n",
    "RUN  apt-get update \\\n",
    "  && apt-get install -y wget vim bzip2\\\n",
    "  && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get -y install curl\n",
    "\n",
    "#Install MINICONDA\n",
    "RUN wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O Miniconda.sh && \\\n",
    "    /bin/bash Miniconda.sh -b -p /opt/conda && \\\n",
    "    rm Miniconda.sh\n",
    "\n",
    "ENV PATH /opt/conda/bin:$PATH\n",
    "\n",
    "RUN conda install numpy scipy matplotlib numba cudatoolkit=9.0 pyculib -y\n",
    "\n",
    "COPY mandelbrot_gpu.py /mandelbrot_gpu.py\n",
    "\n",
    "CMD python3 mandelbrot_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Singularity image\n",
    "-----\n",
    "\n",
    "A Singularity image that can be used to create a container capable of running ```mandelbrot_gpu.py``` can be made from the Docker image we already built and pushed to Docker Hub. This requires a simple definition file such as the below.\n",
    "\n",
    "Singularity Commands to build from the Docker Hub image and the ```Singularity.mandelbrot_gpu``` definition file, then run:\n",
    "\n",
    "1. ```singularity build mandelbrot_gpu.sif Singularity.mandelbrot_gpu```\n",
    "2. ```singularity run --nv mandelbrot_gpu.sif```\n",
    "\n",
    "*Note, the Singularity container needs to be run in the same dir as a file called ```mandelbrot_gpu.py``` for it to run this way. You may wish to not include anything in %files and instead specify the file to run in the run command.*\n",
    "\n",
    "In this case I have built the image with [Singularity Hub](https://www.singularity-hub.org/) by linking it to my [GitHub repo](https://github.com/edwardchalstrey1/turingbench/tree/master/turingbench_python_cuda/mandelbrot_gpu), which contains the definition file, named such that the image will be built on each commit.\n",
    "\n",
    "A container based on the image can then be run on any platform with Singularity with the following command (using the ```--nv``` option to leverage the nvidia GPU):\n",
    "\n",
    "```singularity run --nv shub://singularity-hub.org/edwardchalstrey1/turingbench:mandelbrot_gpu```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Singularity.mandelbrot_gpu\n"
     ]
    }
   ],
   "source": [
    "%%writefile Singularity.mandelbrot_gpu\n",
    "BootStrap: docker \n",
    "From: edwardchalstrey/mandelbrot_gpu\n",
    "\n",
    "%post\n",
    "    apt-get -y update\n",
    "\n",
    "%files      \n",
    "    mandelbrot_gpu.py /mandelbrot_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft Azure Virtual Machine\n",
    "-------\n",
    "\n",
    "To run a container based on Docker or Singularity image we have created in Microsoft Azure requires a virtual machine (VM) with a CUDA-capable GPU and a driver compatible with the CUDA toolkit version you are using, which in our case is 9.0.\n",
    "\n",
    "First, select and create an appropriate VM in Azure. This can be done from the Azure Portal Home by clicking 1) \"Virtual machines\" 2) \"Add\" 3) Choosing the \"Size\" when setting up the VM; I used a Standard NV6 which uses the NVIDIA K80 GPU.\n",
    "\n",
    "Then, after checking the [requirements](https://github.com/NVIDIA/nvidia-docker/wiki/CUDA) an appropriate NVIDIA driver must be installed, which in our case must be a version >= 384.81, because we are using CUDA 9.0.\n",
    "\n",
    "The correct steps will depend on the OS of your VM; if we use an Ubuntu VM, it's as simple as:\n",
    "\n",
    "1. Searching for drivers: ```apt search nvidia-driver```\n",
    "\n",
    "2. Installing the available driver (ensuring first it is a recent enough version): ```sudo apt install nvidia-driver-390```\n",
    "\n",
    "3. Reboot the VM\n",
    "\n",
    "4. Check the above worked with the ```nvidia-smi``` command\n",
    "\n",
    "### Installing the container software on the VM\n",
    "\n",
    "With the NVIDIA driver installed, containers based on the images we created to run [mandelbrot_gpu.py](https://github.com/edwardchalstrey1/turingbench/blob/master/turingbench_python_cuda/mandelbrot_gpu/mandelbrot_gpu.py) can be run on the VM, so long as we have a working installation of either:\n",
    "\n",
    "1. [Docker](https://docs.docker.com/install/) and [NVIDIA-Docker](https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0))\n",
    "\n",
    "2. [Singularity](https://www.sylabs.io/guides/3.2/user-guide/installation.html)\n",
    "\n",
    "### Running our containers\n",
    "\n",
    "We can then run the mandelbrot Python code with each container software as follows:\n",
    "\n",
    "**Docker:**\n",
    "```nvidia-docker run edwardchalstrey/mandelbrot_gpu```\n",
    "\n",
    "**Singularity:**\n",
    "```singularity run --nv shub://singularity-hub.org/edwardchalstrey1/turingbench:mandelbrot_gpu```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JADE HPC\n",
    "----\n",
    "\n",
    "To run a Singularity container based on this image on the JADE HPC, a submission script was required (see below). Instructions on how to set up the script can be found [here](http://docs.jade.ac.uk/en/latest/jade/scheduler/index.html).\n",
    "\n",
    "In JADE, make the submission script executable:\n",
    "```chmod +x jade_sub.sh```\n",
    "\n",
    "Then run with a command such as this:\n",
    "\n",
    "```srun --gres=gpu:1 -p small --pty jade_sub.sh``` (which runs the Singularity container on the small partition with a single GPU)\n",
    "\n",
    "*Note: This works without loading JADE's CUDA module (e.g. ```module load cuda/9.0```) and loading it appears to break the link to the driver. Also if I run ```nvidia-smi``` command before the script*\n",
    "\n",
    "Refer to [JADE-HPC Facility User guide](http://docs.jade.ac.uk/en/latest/index.html) for more info on how to use this HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jade_sub.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile jade_sub.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# set the number of nodes\n",
    "#SBATCH --nodes=1\n",
    "\n",
    "# set max wallclock time\n",
    "#SBATCH --time=00:30:00\n",
    "\n",
    "# set name of job\n",
    "#SBATCH --job-name=echalstrey_singularity_cuda_test1\n",
    "\n",
    "# set number of GPUs\n",
    "#SBATCH --gres=gpu:4\n",
    "\n",
    "# mail alert at start, end and abortion of execution\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "# send mail to this address\n",
    "#SBATCH --mail-user=echalstrey@turing.ac.uk\n",
    "\n",
    "# run the application\n",
    "module load singularity\n",
    "singularity run --nv shub://singularity-hub.org/edwardchalstrey1/turingbench:mandelbrot_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "------\n",
    "\n",
    "I can now run ```mandelbrot_gpu.py``` on these platforms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Platform  | Container  | Mandelbrot creation time in s  |\n",
    "|---|---|---|\n",
    "| Azure (Nvidia K80)  | Docker  | 5.369710  |\n",
    "| Azure (Nvidia K80)  | Singularity 3.2  | 5.734466  |\n",
    "| CSD3 (Nvidia V100)  | Singularity  |   |\n",
    "| JADE (Nvidia P100)  | Singularity 2.4 | 0.934607  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
